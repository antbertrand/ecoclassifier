%!TeX encoding = UTF-8
%!TeX root = ../main.tex
\chapter{Architecture (software)}
\label{chapter:softarchitecture}

The architecture is slightly different for each phase of the project, namely:

\begin{itemize}
    \item Image grabbing and capturing (for dataset-building phase)
    \item Deep-Learning computation (for training phase)
    \item Inference (for inference phase)
\end{itemize}

This repository contains all the required code for the three phases, but this code cannot execute
on the same machine at each step.

Some code require hardware parts to run (dataset building and inference need the cameras), some don't
(deep-learning training doesn't require anything else but a powerful GPU).

The following section is thus split in those different phases.

\section{Image grabbing (training)}

The image grabbing part consists in a software piece that reads from (both) cameras and record enough images to
allow a careful analysis of the captured images.

Capture must be as close as possible to the real conditions of the project.

Capture must retain as much elements as possible but not overflow the hard drives.

Capture is made through an OpenCV + Basler software combination. The general flow is:

\begin{enumerate}
    \item Open cameras, start acquiring (without saving on disk)
    \item If "something moves" on camera, start the recording process
    \item Record as much frames as possible to ensure high resolution acquisition
    \item Close camera (and start over)
    \item Upload material on an Azure blob
\end{enumerate}

This piece of software must be installed on a temporary PC that will be plugged to the cameras.

The software must start when the PC starts (to handle reboots)

The acquired images must be either uploaded or accessed remotely. Thus, the PC needs a permanent or semi-permanent internet connexion.

\section{System architecture}

Inside this operating system runs a \gls{docker} container that will contain the main loop of our program.

The installation procedure for the non-docker part should be ultra-trivial.

\subsection{Main system installation}

Here's the general outline for software installation:

\begin{itemize}
    \item Install a bare-naked Linux-based Operating System
    \item Install \gls{docker} and \texttt{docker-compose} on this OS
    \item Install \texttt{supervisord} to manage automatic launch at start-time (see \url{http://supervisord.org/})
    \item Install the bootstrap code
\end{itemize}

\subsection{Bootstrap code installation}

\todo{Document this}


\section{Program architecture}

The main Majurca Ecoclassifier program runs in a PC that's connected to the machine and to the \gls{plc}.

\todo{Decide if the \gls{heartbeat} is in the same thread or in another thread}

It's composed of a few different component/software blocks that all have a specific purpose.

All hardware manipulations (camera and \gls{plc}) must be done in one and only one place in the code,
thus we need dedicated modules for camera and PLC.

\warningbox{There are (at least) \textbf{two} cameras on a system, so the module must not abstract only
one camera but a camera array. Also, it must be able to control light on a camera if necessary.}

\subsection{Main loop}


\subsubsection{Retry strategy}

If anything goes wrong in the main loop (ie. uncatched exception), we have to go back to where we were.

We use \texttt{tenacity} for this with a retry strategy. In order to have the error reported \textbf{and}
to avoid restarting the whole stack if anything goes wrong, the strategy is as follows:

\begin{itemize}
    \item Wait for 2 seconds then retry
    \item Wait for an exponentially growing time until it reaches 600~seconds (10~minutes) (and retry)
    \item Retry every 600 seconds
    \item After 10 (12? 20?) retries, stop retrying, just propagate the exception \textbf{outside} the container.
        This will stop the container and Docker-compose will take care of restarting it, thus eliminating
        potential memory issues.
\end{itemize}


\subsection{\gls{plc} communication}

Transfers with \gls{plc} must be done in one place only.

We use a singleton class, \texttt{PLC}, which completely abstracts this.

\notebox{We MAY have problems with syncing with the PLC if several connexions are open at the same time.
In this case we'll have to put a lock to make sure it doesn't open several connexions at once.}

\subsection{Cameras management}

There might be several cameras to handle.

Each camera must have a configuration that must be "saved" into the camera.

Issues to handle:

\begin{itemize}
    \item How to generate + save camera configuration?
    \item How to apply configuration to a camera?
    \item As we have (at least) 2 cameras to handle, how, in the configuration system,
        shall we specify which camera to address (of course, configurations are different!)
    \item Synchronous or asynchronous operations
    \item Can we check if a camera output is blurry?
    \item Handling camera heartbeat timeouts (see \url{file:///Applications/pylon%20Programmer's%20Guide%20and%20API%20Reference.app/Contents/Resources/Html/pylon_advanced_topics.html#debugging})
\end{itemize}

\subsubsection{Cameras addressing}

We must find a way to fetch serial number (or IP? Or other?) of a camera in order to address it.

The recommended solution is to use the \textbf{Full name} property.

See this doc extract:

\begin{quotation}
Enumerating and Creating pylon Devices
pylon offers two ways to enumerate and create pylon Devices. The first approach uses the Transport Layer Factory to enumerate cameras across multiple transport layers. The second approach lets a Transport Layer object enumerate and create pylon Devices for a specific transport layer. Before describing the different enumeration schemes, the terms Device Class and Device Info object are introduced.

Device Classes
Each transport layer can create a specific type of pylon Device. For example, the PylonGigE transport layer will create pylon Devices representing GigE Vision cameras. Each type of device is associated with a unique identifier string called Device Class. The device class identifier can be found in the DeviceClass.h header file.

Device Info Objects
The device enumeration procedure returns a list of Device Info objects. The base class for Device Info objects is Pylon::CDeviceInfo. A Device Info object uniquely describes a camera device. Device Info objects are used by a Transport Layer and the Transport Layer Factory to create camera objects representing the device described by the Device Info objects.

FriendlyName:	A human readable name for the device (e.g. the camera's model name). Friendly names are not unique.
FullName:	A unique identifier for the device. No two devices will have the same full name.
VendorName:	The name of the vendor.
DeviceClass:	Each transport layer can create a specific type (or class) of camera devices (e.g. IIDC 1394 or GigE Vision devices). The device types are identified by the Device Class property.
SerialNumber:	The device's serial number. The availability of the device serial number is not guaranteed during the enumeration process, so the Serial Number Property may be undefined.
UserDefinedName:	For some device classes, it is possible to assign a user defined name to a camera device. The value of this property is not necessarily unique.
DeviceFactory:	The unique full name of the Transport Layer object that can create the device.
In addition, specific transport layers will require additional properties. These properties can be accessed in a generic way by using the Pylon::IProperties interface.
\end{quotation}

Hence we must find a way to grab and store camera full names at config time and store them in constants for later use.

The recommended approach here is to store them in a file in the source (like \texttt{settings.py} ) that we'll update for each additional deployment. We use \texttt{CAMERA\_HZ\_SERIALS} and \texttt{CAMERA\_VT\_SERIALS} variables for these.

\subsubsection{Configuration management}

\todo{This has to be done}

\subsubsection{Synchronous / Asynchronous operations}

In order to give the best possible performance, we'll have to manage a synchronous / asynchronous mode
for cameras management.

Two approaches here:

\begin{itemize}
    \item Decide that everything is synchronous: we open the camera, grab the frames one by one
        and analyze them on-the-fly
    \item Use a fully asynchronous approach with a file buffer: we capture all frames, save them,
        and it's up to the controlling program to open a file and read it.
        If asynchronous capture is not a big deal, we'd still have to control the camera from the
        main program (start acquiring / stop acquiring, manage lights, etc).
        One intermediate solution could use 2 different containers: one to handle ONLY the camera
        given the PLC status, and one other to handle control (also by reading PLC status tables).
\end{itemize}

First version will OBVIOUSLY use the first approach (synchronous operations). Second version
could use the second approach in order to maximize efficiency even if image analysis takes
a little time.

\subsection{Barcode reading}

We use \url{https://github.com/NaturalHistoryMuseum/pyzbar/}.

For information about how to optimize barcode reading in potentially difficult conditions, see \url{http://zbar.sourceforge.net/iphone/sdkdoc/optimizing.html}


\section{Maintenance, diagnosis}

\subsection{Automatic restart}

\todo{Decide what's the best policy here}

We have to use either Docker's auto-restart or Supervisor's auto-restart policy here.

For Docker's policies, see \url{https://docs.docker.com/config/containers/start-containers-automatically/}


\subsection{Automatic update}

\todo{Describe here}



\subsection{Remote access}

Remote access can be done via Dinatec's VPN. Then the machine can be accessed via \texttt{ssh} and only \texttt{ssh}.

\notebox{Dinatec's software to access the VPN is called \texttt{Sinema RC}}


\section{Bootstrap module}

\subsection{Dependencies}

The OS is Linux (headless), Debian or Ubuntu.

\todo{Specify OS needs here}

We also need:

\begin{itemize}
    \item Docker, >= 18.0.9
    \item Docker-compose, >= 1.23.2
\end{itemize}



\section{Containers}


\subsection{Container: \texttt{ecoclassifier-main}}

This is the container holding the main camera program.

It has the main loop.



\section{Dependencies}

\notebox{If we have performance issues and/or problems to keep up with the \gls{heartbeat},
we could add another container to handle the heartbeat specifically.}

Here's the list of software that must be configured on the container:

\begin{itemize}
    \item Python >= 3.6
    \item OpenCV
    \item Snap7 software (for \gls{plc} communication)
    \item Basler software (bundled with our Dockerfile!)
    \item Semi-async mode (main loop for image capture, async mode for the upload part)
    \item Keras
    \item Usual requirements.txt additional packages
    \item Pyzbar
\end{itemize}

Plus we have to enable the following service/packages/libraries:

\begin{itemize}
    \item \texttt{Sentry} (see \url{https://sentry.io}) to report exceptions
    \item \texttt{timeout-decorator} (see \url{https://github.com/pnpnpn/timeout-decorator})
    \item \texttt{Tenacity} (see \url{https://github.com/jd/tenacity})
\end{itemize}
