{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import all the Keras machinery we need\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare our training / validation / etc set\n",
    "def getData():\n",
    "    filename = './dataset/majurca-ecoclassifier-assets.json'\n",
    "    im_path = []\n",
    "    labels = []\n",
    "    k=0\n",
    "\n",
    "    #Read JSON data into the datastore variable\n",
    "    if filename:\n",
    "        with open(filename, 'r') as f:\n",
    "            list_info = json.load(f)\n",
    "\n",
    "    str_filter = '192-168-0-31' # to filter certain files\n",
    "    #print(list_info[2443]['id'])\n",
    "    #print(len(list_info))\n",
    "\n",
    "    for dict in list_info:\n",
    "        #print(k)\n",
    "        if str_filter in dict['path']:\n",
    "            if dict['tag_slugs'] != [] and dict['tag_slugs'] in [['godet-vide'], ['pet-fonce'], ['pet-clair']]:\n",
    "                labels.append(dict['tag_slugs'][0])\n",
    "                im_path.append(dict['thumbnail_320x200_path'])\n",
    "            else:\n",
    "                #print('no label',dict['path'])\n",
    "                k=k+1\n",
    "        else:\n",
    "            #print('wrong camera',dict['path'])\n",
    "            k=k+1\n",
    "\n",
    "    print('{} images were ignored'.format(k))\n",
    "    print(len(im_path),len(labels))\n",
    "    return im_path, labels\n",
    "\n",
    "def splitData(X,y):\n",
    "    output_dir = './dataset_split'\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    #Create folder for the test and training split\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "        os.mkdir(output_dir + '/test')\n",
    "        os.mkdir(output_dir + '/train')\n",
    "    else:\n",
    "        print(\"Warning: output dir {} already exists\".format(output_dir))\n",
    "\n",
    "    #Copying files into test and train folder\n",
    "    label_count_test = []\n",
    "    label_count_train = []\n",
    "\n",
    "    for file in X_test:\n",
    "        #file = file.replace(':','/')\n",
    "        os.system('cp ./dataset/'+ file + ' ' + output_dir + '/test/' + file)\n",
    "\n",
    "    for file in X_train:\n",
    "        #file = file.replace(':','/')\n",
    "        os.system('cp ./dataset/'+ file + ' ' + output_dir + '/train/' + file)\n",
    "\n",
    "    #print(Counter(y_train), Counter(y_test))\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def splitValidation(X,y):\n",
    "    X_train, X_vali, y_train, y_vali = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    return X_train, X_vali, y_train, y_vali\n",
    "\n",
    "#files_all, labels_all = getData()\n",
    "#print(type(files_all[3]),labels_all[3])\n",
    "#X_try, X_test, y_try, y_test = splitData(files_all,labels_all)\n",
    "#X_train, X_vali, y_train, y_vali = splitValidation(X_try, y_try)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset/wsEN4iv2SliFUuYNXIM-5Q_mN01z2Y0RASRi1KBB0tY2Q_320x200.png\n"
     ]
    }
   ],
   "source": [
    "# We build our (X, y) set. We ignore test set yet (laziness)\n",
    "with open(\"./dataset/majurca-ecoclassifier-assets.json\", \"r\") as source:\n",
    "    assets = json.load(source)\n",
    "    \n",
    "# Populate our target variables. X is gonna be filename, y the class\n",
    "X = []\n",
    "y = []\n",
    "target_labels = set((\"pet-clair\", \"pet-fonce\", \"godet-vide\", ))\n",
    "for asset in assets:\n",
    "    # Skip what's not from OUR camera\n",
    "    if not \"192-168-0-31\" in asset['path']:\n",
    "        continue\n",
    "    intersection = target_labels.intersection(asset['tag_slugs'])\n",
    "    if not intersection:\n",
    "        continue\n",
    "    label = intersection.pop()\n",
    "    str = asset['thumbnail_320x200_path']\n",
    "    str = str.replace(':','_')\n",
    "    X.append(\"./dataset/{}\".format(str))\n",
    "    y.append(label)\n",
    "print(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 580 images belonging to 3 classes.\n",
      "Found 145 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "n_train_samples = len(X) * 0.8\n",
    "n_val_samples = len(X) * 0.2\n",
    "batch_size = 32\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2\n",
    ")\n",
    "dataset_info = {'filename': X, 'class': y}\n",
    "dataframe = pd.DataFrame(dataset_info)\n",
    "dataframe\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe,\n",
    "    subset=\"training\",\n",
    "    class_mode=\"categorical\",\n",
    "    classes=target_labels,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe,\n",
    "    subset=\"validation\",\n",
    "    class_mode=\"categorical\",\n",
    "    classes=target_labels,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'godet-vide': 0, 'pet-clair': 1, 'pet-fonce': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abert/.virtualenvs/test/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model loaded.\n",
      "WARNING:tensorflow:From /home/abert/.virtualenvs/test/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/abert/.virtualenvs/test/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/6\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.9951 - acc: 0.4080 - val_loss: 0.9598 - val_acc: 0.3203\n",
      "Epoch 2/6\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.7841 - acc: 0.5714 - val_loss: 0.7714 - val_acc: 0.7434\n",
      "Epoch 3/6\n",
      "18/18 [==============================] - 16s 876ms/step - loss: 0.5995 - acc: 0.7587 - val_loss: 0.3604 - val_acc: 0.8584\n",
      "Epoch 4/6\n",
      "18/18 [==============================] - 16s 875ms/step - loss: 0.3366 - acc: 0.8747 - val_loss: 0.1750 - val_acc: 0.9469\n",
      "Epoch 5/6\n",
      "18/18 [==============================] - 16s 875ms/step - loss: 0.1834 - acc: 0.9356 - val_loss: 0.1869 - val_acc: 0.9469\n",
      "Epoch 6/6\n",
      "18/18 [==============================] - 16s 877ms/step - loss: 0.1483 - acc: 0.9484 - val_loss: 0.1680 - val_acc: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f998ee7fba8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION 3 VGG16 simple sans prÃ©entrainement du top classifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False,input_shape = (224,224,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "\n",
    "#top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-5),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "#K.clear_session()\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=n_train_samples // batch_size,\n",
    "    epochs=6,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_val_samples // batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec K-Fold CROSS VALIDATION ( a faire)\n",
    "'''\n",
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "    print('\\nFold ',j)\n",
    "    X_train_cv = X_train[train_idx]\n",
    "    y_train_cv = y_train[train_idx]\n",
    "    X_valid_cv = X_train[val_idx]\n",
    "    y_valid_cv= y_train[val_idx]\n",
    "    \n",
    "    name_weights = \"final_model_fold\" + str(j) + \"_weights.h5\"\n",
    "    callbacks = get_callbacks(name_weights = name_weights, patience_lr=10)\n",
    "    generator = gen.flow(X_train_cv, y_train_cv, batch_size = batch_size)\n",
    "    model = get_model()\n",
    "    model.fit_generator(\n",
    "                generator,\n",
    "                steps_per_epoch=len(X_train_cv)/batch_size,\n",
    "                epochs=15,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data = (X_valid_cv, y_valid_cv),\n",
    "                callbacks = callbacks)\n",
    "    \n",
    "    model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=n_train_samples // batch_size,\n",
    "                epochs=6,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=n_val_samples // batch_size,\n",
    ")\n",
    "    \n",
    "    print(model.evaluate(X_valid_cv, y_valid_cv))\n",
    "# Leeeet's traaaaaaaaiiiiin!!!!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vgg16_v1.h5')\n",
    "#Y_pred = cnnmodel.predict_generator(validation_generator, n_val_samples // batch_size+1)\n",
    "#y_pred = np.argmax(Y_pred, axis=1)\n",
    "#validation_generator.classes\n",
    "#y_pred\n",
    "n_correct = 0\n",
    "#import pdb;pdb.set_trace()\n",
    "for _val_xs, _val_ys in validation_generator:#n_validation_samples // batch_size):\n",
    "    for idx in range(len(_val_ys)):\n",
    "        img = _val_xs[idx]\n",
    "        _y = np.argmax(_val_ys[idx], axis=0)\n",
    "        pred = np.argmax(model.predict(np.expand_dims(img, axis=0)), axis=1)\n",
    "        print(_y, pred, pred == _y)\n",
    "#        n_correct += pred == _y and 1 or 0\n",
    "#print(\"Correct answers = %0.2f%%\" % (n_correct / len(validation_generator.classes) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          ):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    cmap = plt.cm.jet\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, '{:.2f}'.format(cm[i, j]), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "#Confusion Matrix and Classification Report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "Y_pred = cnnmodel.predict_generator(validation_generator, n_val_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_labels))\n",
    "\n",
    "# Sample prediction\n",
    "for idx in range(10):\n",
    "    img = image.load_img(X[idx], target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    pred = cnnmodel.predict(x)\n",
    "    print(X[idx], list(target_labels).index(y[idx]), np.argmax(pred), pred)\n",
    "    \n",
    "# Plot a pretty confusion matrix\n",
    "#np.set_printoptions(precision=2)\n",
    "#dev_feats = read_dataset('valid')\n",
    "#predictions = emotion_classifier.predict_classes(dev_feats)\n",
    "#te_labels = get_labels('valid')\n",
    "#conf_mat = confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "#plt.figure()\n",
    "#plot_confusion_matrix(conf_mat, classes=target_labels)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_test",
   "language": "python",
   "name": "kernel_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
